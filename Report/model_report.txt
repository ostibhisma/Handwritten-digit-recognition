
 Accuracy = 0.964 

 Confusion Matrix = 
[[201   0   2   0   0   2   0   0   0   0]
 [  0 217   1   0   0   0   0   0   0   0]
 [  1   0 184   0   3   0   3   1   0   0]
 [  0   0   5 192   0   1   0   2   1   0]
 [  0   0   1   0 198   0   4   1   0   1]
 [  0   2   0   1   2 190   3   0   0   0]
 [  1   1   1   0   1   1 181   0   0   0]
 [  0   1   2   0   1   0   0 187   0   2]
 [  0   1   2   4   1   2   1   1 179   0]
 [  2   1   0   1   5   0   0   1   2 199]]

 Classification Report = 
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       205
           1       0.97      1.00      0.98       218
           2       0.93      0.96      0.94       192
           3       0.97      0.96      0.96       201
           4       0.94      0.97      0.95       205
           5       0.97      0.96      0.96       198
           6       0.94      0.97      0.96       186
           7       0.97      0.97      0.97       193
           8       0.98      0.94      0.96       191
           9       0.99      0.94      0.96       211

    accuracy                           0.96      2000
   macro avg       0.96      0.96      0.96      2000
weighted avg       0.96      0.96      0.96      2000
